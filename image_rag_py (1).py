# -*- coding: utf-8 -*-
"""image_rag.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lDkXOIV0cc6WDNKDOur4z6HGL69q4DXV
"""

import matplotlib
matplotlib.use("Agg")

from pdf2image import convert_from_bytes
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import torch
import numpy as np
import faiss
import matplotlib.pyplot as plt
import streamlit as st


MODEL_NAME = "openai/clip-vit-base-patch32"
DEVICE = "cpu"
MAX_PAGES = 5
TOP_K = 3

@st.cache_resource
def load_clip():
    model = CLIPModel.from_pretrained(MODEL_NAME).to(DEVICE)
    processor = CLIPProcessor.from_pretrained(MODEL_NAME)
    model.eval()
    return model, processor

clip_model, clip_processor = load_clip()

def get_image_embedding(image: Image.Image):
    inputs = clip_processor(images=image, return_tensors="pt").to(DEVICE)
    with torch.no_grad():
        emb = clip_model.get_image_features(**inputs)
    emb = emb / emb.norm(dim=-1, keepdim=True)
    return emb


def build_faiss_index(embeddings, images):
    emb_np = embeddings.detach().cpu().numpy().astype("float32")

    norms = np.linalg.norm(emb_np, axis=1, keepdims=True)
    norms[norms == 0] = 1
    emb_np /= norms

    dim = emb_np.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(emb_np)

    mapping = {i: img for i, img in enumerate(images)}
    return index, mapping

def retrieve(query_emb, index, mapping, k=3):
    q = query_emb.detach().cpu().numpy().astype("float32")
    q /= np.linalg.norm(q, axis=1, keepdims=True)

    D, I = index.search(q, k)
    return [
        {"image": mapping[int(i)], "score": float(s)}
        for i, s in zip(I[0], D[0])
    ]


st.set_page_config(page_title="CLIP Image RAG", layout="wide")
st.title("ðŸ“„ Image Retrieval from PDF using CLIP")
st.markdown("Upload a PDF â†’ Search similar images using a query image")

st.sidebar.header("Upload PDF")
pdf_file = st.sidebar.file_uploader("PDF file", type=["pdf"])

if pdf_file:
    images = convert_from_bytes(
        pdf_file.read(),
        dpi=200,
        first_page=1,
        last_page=MAX_PAGES
    )
    st.sidebar.success(f"{len(images)} pages loaded")

query_file = st.file_uploader("Upload query image", type=["png", "jpg", "jpeg"])

if pdf_file and query_file:
    with st.spinner("Creating embeddings..."):
        pdf_embeddings = []
        for img in images:
            img = img.resize((512, 512))
            pdf_embeddings.append(get_image_embedding(img))
        pdf_embeddings = torch.cat(pdf_embeddings, dim=0)

        index, mapping = build_faiss_index(pdf_embeddings, images)

    query_image = Image.open(query_file).convert("RGB")
    query_embedding = get_image_embedding(query_image)

    results = retrieve(query_embedding, index, mapping, TOP_K)

    st.subheader("Query Image")
    st.image(query_image, width=300)

    st.subheader("Retrieved Images")
    cols = st.columns(TOP_K)

    for col, res in zip(cols, results):
        with col:
            st.image(res["image"], use_column_width=True)
            st.caption(f"Score: {res['score']:.3f}")